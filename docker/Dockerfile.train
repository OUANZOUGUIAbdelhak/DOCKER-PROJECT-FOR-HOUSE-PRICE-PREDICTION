# ============================================================================
# TRAINING DOCKERFILE
# ============================================================================
# Purpose: Build Docker image for ML model training
#
# Key Concepts:
# - Each instruction creates a layer (cached for faster rebuilds)
# - Order matters: Put frequently changing layers last
# - Multi-stage builds can reduce final image size (not used here for simplicity)
# ============================================================================

# ----------------------------------------------------------------------------
# BASE IMAGE
# ----------------------------------------------------------------------------
# FROM: Specifies base image to start from
# python:3.9-slim: Official Python image, slim variant (smaller size)
#
# Why python:3.9-slim?
# - Contains Python 3.9 + essential system libraries
# - Slim = minimal OS (Debian-based, ~150MB vs ~900MB for full Python image)
# - Good balance: Small size + compatibility
#
# Alternatives:
# - python:3.9: Full image (larger, more tools)
# - python:3.9-alpine: Even smaller (Alpine Linux, ~50MB) but compatibility issues
# - ubuntu:20.04 + manual Python install (more control, more work)
# ----------------------------------------------------------------------------
FROM python:3.9-slim

# ----------------------------------------------------------------------------
# METADATA
# ----------------------------------------------------------------------------
# LABEL: Adds metadata to image (optional but good practice)
LABEL maintainer="ML Engineer"
LABEL description="Training container for House Price Prediction ML Pipeline"
LABEL version="1.0"

# ----------------------------------------------------------------------------
# WORKDIR
# ----------------------------------------------------------------------------
# WORKDIR: Sets working directory for subsequent commands
# Creates directory if it doesn't exist
# All relative paths in RUN/COPY/CMD are relative to this directory
#
# Why /app?
# - Standard convention for application code
# - Keeps things organized
# - Avoids cluttering root directory
# ----------------------------------------------------------------------------
WORKDIR /app

# ----------------------------------------------------------------------------
# SET PYTHON PATH
# ----------------------------------------------------------------------------
# ENV: Sets environment variable (available at runtime)
# PYTHONPATH: Tells Python where to look for modules
# /app: Our working directory, so Python can find 'src' and 'inference' modules
#
# Why this is needed:
# - When we do 'from src.data_loader import DataLoader', Python needs to find 'src'
# - By default, Python only looks in current directory and installed packages
# - Adding /app to PYTHONPATH makes 'src' and 'inference' importable
# ----------------------------------------------------------------------------
ENV PYTHONPATH=/app

# ----------------------------------------------------------------------------
# INSTALL SYSTEM DEPENDENCIES
# ----------------------------------------------------------------------------
# RUN: Executes command during image BUILD (not container runtime)
# Creates a new layer
#
# Why install system packages first?
# - Some Python packages need system libraries (e.g., pandas needs libgfortran)
# - Install before Python packages to avoid rebuilds
#
# What are these packages?
# - build-essential: C/C++ compiler (needed for some Python packages)
# - gcc, g++: Compilers
# - libgfortran5: Fortran library (needed by numpy/scipy)
# - &&: Chains commands (next only runs if previous succeeds)
# - \: Line continuation (for readability)
# - -y: Auto-confirm apt-get (non-interactive)
# - rm -rf /var/lib/apt/lists/*: Clean up apt cache (reduces image size)
# ----------------------------------------------------------------------------
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        build-essential \
        gcc \
        g++ \
        libgfortran5 && \
    rm -rf /var/lib/apt/lists/*

# ----------------------------------------------------------------------------
# COPY REQUIREMENTS FIRST
# ----------------------------------------------------------------------------
# COPY: Copies files from host to image (at BUILD time)
# Why copy requirements.txt first?
# - Dependencies change less frequently than code
# - Docker caches layers
# - If requirements.txt unchanged, pip install layer is cached (faster rebuilds)
# - If code changes, we don't reinstall dependencies
#
# Layer Caching Strategy:
# 1. Copy requirements.txt (changes rarely)
# 2. Install dependencies (expensive, cached if requirements.txt unchanged)
# 3. Copy code (changes frequently)
# 4. Run training (changes frequently)
# ----------------------------------------------------------------------------
COPY requirements.txt .

# ----------------------------------------------------------------------------
# INSTALL PYTHON DEPENDENCIES
# ----------------------------------------------------------------------------
# RUN: Install Python packages
# --no-cache-dir: Don't cache pip downloads (reduces image size)
# -r requirements.txt: Install from requirements file
#
# Why --no-cache-dir?
# - Pip cache can be large (~100-200MB)
# - Not needed in final image
# - Reduces image size
#
# What if installation fails?
# - Build fails with error message
# - Check requirements.txt for typos/version conflicts
# ----------------------------------------------------------------------------
RUN pip install --no-cache-dir -r requirements.txt

# ----------------------------------------------------------------------------
# COPY SOURCE CODE
# ----------------------------------------------------------------------------
# COPY: Copy application code
# src/ /app/src/: Copy src directory to /app/src/ in image
# inference/ /app/inference/: Copy inference directory
#
# Why copy code last?
# - Code changes most frequently
# - Dependencies layer is cached (faster rebuilds)
# - Only code layer rebuilds when code changes
#
# What gets copied?
# - Everything in src/ and inference/ directories
# - .dockerignore excludes unnecessary files (data, models, .git, etc.)
# ----------------------------------------------------------------------------
COPY src/ /app/src/
COPY inference/ /app/inference/

# ----------------------------------------------------------------------------
# CREATE DIRECTORIES FOR VOLUMES
# ----------------------------------------------------------------------------
# RUN: Create directories that will be mounted as volumes
# Why create them?
# - If volume mount fails, directories still exist
# - Prevents errors from missing directories
# - Good practice for volume mount points
#
# Note: These directories will be OVERWRITTEN by volume mounts at runtime
# But creating them ensures they exist if volumes aren't mounted
# ----------------------------------------------------------------------------
RUN mkdir -p /app/models /app/data/raw /app/data/processed

# ----------------------------------------------------------------------------
# DEFAULT COMMAND
# ----------------------------------------------------------------------------
# CMD: Default command when container STARTS (runtime, not build)
# Can be overridden: docker run image echo "hello"
#
# Why CMD instead of ENTRYPOINT?
# - CMD allows overriding (more flexible)
# - ENTRYPOINT always runs (less flexible)
# - For training, CMD is better (might want to run different scripts)
#
# What happens when container starts?
# 1. Container starts from this image
# 2. Executes: python src/train.py
# 3. Training runs
# 4. Model saved to /app/models (which is mapped to host via volume)
# 5. Container stops
# ----------------------------------------------------------------------------
CMD ["python", "src/train.py"]

# ----------------------------------------------------------------------------
# DOCKERFILE BEST PRACTICES SUMMARY
# ----------------------------------------------------------------------------
# ✅ Order: System deps → Requirements → Code (for caching)
# ✅ Clean up: Remove apt cache, use --no-cache-dir
# ✅ Use WORKDIR: Keeps paths organized
# ✅ Use CMD: Allows flexibility
# ✅ Create volume directories: Prevents errors
# ✅ Use .dockerignore: Excludes unnecessary files
#
# ❌ Don't: Install packages in CMD (runs every container start, not cached)
# ❌ Don't: Copy data into image (use volumes instead)
# ❌ Don't: Store secrets in image (use environment variables or secrets)
# ❌ Don't: Run as root (use USER instruction for production)
# ----------------------------------------------------------------------------
